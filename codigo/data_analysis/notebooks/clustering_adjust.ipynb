{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import community as community_louvain\n",
    "from sklearn.metrics.pairwise import euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para clusterização baseada em grafos\n",
    "def graph_based_clustering(data, min_size, max_size):\n",
    "    # Construir um grafo a partir dos dados\n",
    "    G = nx.Graph()\n",
    "    for i in data.index:\n",
    "        G.add_node(i, latitude=data.at[i, 'LATITUDE'], longitude=data.at[i, 'LONGITUDE'])\n",
    "    \n",
    "    # Adicionar arestas com base na similaridade entre os pontos (distância euclidiana)\n",
    "    coords = data[['LATITUDE', 'LONGITUDE']].values\n",
    "    distances = euclidean_distances(coords, coords)\n",
    "    for i in range(len(data)):\n",
    "        for j in range(i+1, len(data)):\n",
    "            similarity = 1 / (1 + distances[i, j])  # Inverso da distância para similaridade\n",
    "            G.add_edge(i, j, weight=similarity)\n",
    "    \n",
    "    # Executar a detecção de comunidades otimizando a modularidade\n",
    "    partition = community_louvain.best_partition(G)\n",
    "    \n",
    "    # Construir clusters a partir dos resultados da detecção de comunidades\n",
    "    clusters = {}\n",
    "    for node, cluster_id in partition.items():\n",
    "        if cluster_id not in clusters:\n",
    "            clusters[cluster_id] = []\n",
    "        clusters[cluster_id].append(node)\n",
    "    \n",
    "    # Filtrar clusters que não atendem às restrições de tamanho\n",
    "    filtered_clusters = {cluster_id: nodes for cluster_id, nodes in clusters.items()\n",
    "                         if min_size <= len(nodes) <= max_size}\n",
    "    \n",
    "    return filtered_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leitura dos dados\n",
    "data = pd.read_csv(\"../data_source/amostra_total.csv\", sep=';')\n",
    "data = data[[\"INDICE\", \"LATITUDE\", \"LONGITUDE\", \"LOGRADOURO\", \"NUMERO\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir tamanhos mínimo e máximo de cluster\n",
    "min_size = 300\n",
    "max_size = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executar a clusterização\n",
    "clusters = graph_based_clustering(data, min_size, max_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibir resultados\n",
    "for cluster_id, nodes in clusters.items():\n",
    "    print(f\"Cluster {cluster_id}: {len(nodes)} pontos\")\n",
    "    print(data.loc[nodes])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
